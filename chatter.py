"""KokoroFlowChatter æ ¸å¿ƒèŠå¤©å™¨ã€‚

å®ç°å®Œæ•´çš„å¿ƒç†æ´»åŠ¨æµå¯¹è¯å¾ªç¯ï¼š
1. æ„å»º LLM ä¸Šä¸‹æ–‡ï¼ˆç³»ç»Ÿæç¤º + æ´»åŠ¨æµ + æœªè¯»æ¶ˆæ¯ï¼‰
2. ç»´æŠ¤ LLMResponse é“¾ï¼ˆresponse = request â†’ loopï¼‰
3. é€šè¿‡ç­–ç•¥å±‚è§£æå“åº”å’Œæ„å»º payload
4. æ‰§è¡ŒåŠ¨ä½œå¹¶ç®¡ç†ç­‰å¾…çŠ¶æ€
5. è¶…æ—¶åé‡æ–°æ³¨å…¥ä¸Šä¸‹æ–‡ç»§ç»­å¯¹è¯

ä¸¥æ ¼éµå¾ª DefaultChatter._execute_enhanced() çš„ response é“¾æ¨¡å¼ã€‚
"""

from __future__ import annotations

import time
from typing import TYPE_CHECKING, Any, AsyncGenerator

from src.app.plugin_system.api.llm_api import (
    create_llm_request,
    create_tool_registry,
    get_model_set_by_task,
)
from src.app.plugin_system.api.log_api import get_logger
from src.core.components.base import (
    BaseChatter,
    Failure,
    Stop,
    Success,
    Wait,
)
from src.core.components.types import ChatType
from src.core.config import get_core_config
from src.kernel.llm import Content, LLMContextManager, LLMPayload, ROLE, Text, ToolResult

if TYPE_CHECKING:
    from src.core.components.base.plugin import BasePlugin
    from src.core.models.stream import ChatStream

    from .config import KFCConfig
    from .models import StrategyResult
    from .session import KFCSession, KFCSessionStore
    from .strategies.base import ChatStrategy

logger = get_logger("kfc_chatter")

# æ§åˆ¶æµæ ‡è®°
_KFC_REPLY = "kfc_reply"


class KokoroFlowChatter(BaseChatter):
    """KokoroFlowChatter æ ¸å¿ƒèŠå¤©å™¨ã€‚

    åŸºäºå¿ƒç†æ´»åŠ¨æµçš„å¯¹è¯æ¨¡å‹ï¼š
    - ç»´æŠ¤ LLMResponse é“¾è´¯ç©¿æ•´ä¸ª execute() ç”Ÿå‘½å‘¨æœŸ
    - é€šè¿‡ç­–ç•¥å±‚æ„å»º payload å’Œè§£æå“åº”
    - æ´»åŠ¨æµä¸ºæŒä¹…åŒ–å®¡è®¡æ—¥å¿—ï¼ŒLLM ä¸Šä¸‹æ–‡é€šè¿‡ response é“¾è‡ªåŠ¨ç§¯ç´¯
    - æ”¯æŒ unified / split ä¸¤ç§æ‰§è¡Œæ¨¡å¼
    """

    chatter_name: str = "kokoro_flow_chatter"
    chatter_description: str = (
        "å¿ƒç†æ´»åŠ¨æµèŠå¤©å™¨ï¼Œæ¨¡æ‹ŸçœŸå®äººç±»çš„è¿ç»­å¿ƒç†æ´»åŠ¨å’Œå¯¹è¯èŠ‚å¥"
    )

    associated_platforms: list[str] = []
    chat_type: ChatType = ChatType.PRIVATE
    dependencies: list[str] = []

    def _get_config(self) -> KFCConfig:
        """è·å– KFC é…ç½®ã€‚"""
        from .config import KFCConfig

        plugin_config = getattr(self.plugin, "config", None)
        if plugin_config and isinstance(plugin_config, KFCConfig):
            return plugin_config
        return KFCConfig()

    def _get_strategy(self) -> ChatStrategy:
        """æ ¹æ®é…ç½®è·å–ç­–ç•¥å®ä¾‹ã€‚"""
        from .strategies import SplitStrategy, UnifiedStrategy

        config = self._get_config()
        if config.general.mode == "split":
            return SplitStrategy()
        return UnifiedStrategy()

    async def _get_session(self) -> KFCSession:
        """è·å–å½“å‰ stream çš„ Sessionï¼ˆæŒæœ‰ per-stream é”ï¼‰ã€‚"""
        session_store = self._get_session_store()
        async with session_store.lock(self.stream_id):
            return await session_store.get_or_create(self.stream_id)

    def _get_session_store(self) -> KFCSessionStore:
        """è·å– Session Storeã€‚"""
        plugin = self.plugin
        store = getattr(plugin, "_session_store", None)
        if store is not None:
            return store

        from .session import KFCSessionStore

        new_store = KFCSessionStore()
        plugin._session_store = new_store  # type: ignore[attr-defined]
        return new_store

    async def execute(self) -> AsyncGenerator[Wait | Success | Failure | Stop, None]:
        """æ‰§è¡ŒèŠå¤©å™¨çš„å¯¹è¯å¾ªç¯ã€‚

        æ ¸å¿ƒæµç¨‹ï¼š
        1. åˆå§‹åŒ– LLM è¯·æ±‚ï¼ˆç³»ç»Ÿæç¤º + å·¥å…·æ³¨å†Œï¼‰
        2. response = requestï¼ˆå»ºç«‹ response é“¾ï¼‰
        3. å¾ªç¯ï¼šè¯»å–æœªè¯» â†’ ç­–ç•¥æ„å»º payload â†’ LLM è°ƒç”¨ â†’ è§£æ â†’ æ‰§è¡ŒåŠ¨ä½œ
        4. ç­‰å¾…è¶…æ—¶åæ³¨å…¥è¶…æ—¶ payload ç»§ç»­ response é“¾

        Yields:
            Wait | Success | Failure | Stop: æ‰§è¡Œç»“æœ
        """
        from src.core.managers.stream_manager import get_stream_manager

        # â”€â”€ åˆå§‹åŒ– â”€â”€
        stream_manager = get_stream_manager()
        chat_stream = await stream_manager.activate_stream(self.stream_id)
        config = self._get_config()
        strategy = self._get_strategy()
        session = await self._get_session()

        # â”€â”€ æ„å»º LLM è¯·æ±‚ â”€â”€
        model_set = get_model_set_by_task(config.general.model_task)
        if not model_set:
            logger.error("æ— æ³•è·å–æ¨¡å‹é…ç½®")
            yield Failure("æ¨¡å‹é…ç½®é”™è¯¯ï¼šæœªæ‰¾åˆ° model_task é…ç½®")
            return

        # split æ¨¡å¼ï¼šå†³ç­–æ­¥ä½¿ç”¨è½»é‡çº§ sub_actorï¼Œå›å¤æ­¥ä½¿ç”¨ä¸»æ¨¡å‹
        is_unified = config.general.mode != "split"
        decision_model_set = None
        if not is_unified:
            decision_model_set = get_model_set_by_task("sub_actor")
            if not decision_model_set:
                logger.warning("sub_actor æ¨¡å‹ä¸å¯ç”¨ï¼Œsplit å†³ç­–æ­¥é™çº§ä¸ºä¸»æ¨¡å‹")
                decision_model_set = model_set

        context_manager = LLMContextManager(
            max_payloads=config.prompt.max_context_payloads
        )
        request = create_llm_request(
            model_set,
            "kokoro_flow_chatter",
            context_manager=context_manager,
        )

        # â”€â”€ æ³¨å†Œç¬¬ä¸‰æ–¹å·¥å…·ï¼ˆè¿‡æ»¤ KFC æ ¸å¿ƒåŠ¨ä½œ + å…¶ä»– chatter ä¸“å±åŠ¨ä½œï¼‰ â”€â”€
        usables = await self.get_llm_usables()
        usables = await self.modify_llm_usables(usables)

        _KFC_TOOL_NAMES = {_KFC_REPLY}
        if is_unified:
            pre_filter_count = len(usables)
            filtered_usables = []
            for u in usables:
                # æ’é™¤ KFC æ ¸å¿ƒåŠ¨ä½œ
                if getattr(u, "action_name", None) in _KFC_TOOL_NAMES:
                    continue
                # æ’é™¤å…¶ä»– chatter ä¸“å±çš„ Actionï¼ˆchatter_allow ä¸­æ²¡æœ‰æœ¬ chatterï¼‰
                chatter_allow = getattr(u, "chatter_allow", None)
                if chatter_allow and self.chatter_name not in chatter_allow:
                    continue
                filtered_usables.append(u)
            usables = filtered_usables
            if config.debug.show_prompt:
                kept_names = [
                    getattr(u, "action_name", None) or getattr(u, "tool_name", None) or type(u).__name__
                    for u in usables
                ]
                logger.debug(
                    f"[KFC] å·¥å…·è¿‡æ»¤: {pre_filter_count} â†’ {len(usables)} | "
                    f"ä¿ç•™: {kept_names}"
                )

        usable_map = create_tool_registry(usables)

        # ä¸ä½¿ç”¨åŸç”Ÿ Tool Callingï¼ˆé¿å… tool_choice å†²çª + thought æ³„éœ²ï¼‰
        # æ”¹ä¸ºå°†ç¬¬ä¸‰æ–¹å·¥å…·æè¿°æ³¨å…¥ç³»ç»Ÿæç¤ºè¯çš„ JSON åŠ¨ä½œç±»å‹ä¸­
        tool_schemas: list[dict] = []
        if usable_map.get_all():
            tool_schemas = [t.to_schema() for t in usable_map.get_all()]
            if config.debug.show_prompt:
                tool_schema_names = [
                    s.get("function", s).get("name", "?") for s in tool_schemas
                ]
                logger.debug(
                    f"[KFC] æ³¨å…¥ {len(tool_schema_names)} ä¸ªå·¥å…·åˆ° JSON åŠ¨ä½œç±»å‹: "
                    f"{tool_schema_names}"
                )

        # ç³»ç»Ÿæç¤ºè¯ï¼ˆå«åŠ¨æ€å·¥å…·æè¿°ï¼‰
        from .prompts.builder import KFCPromptBuilder

        prompt_builder = KFCPromptBuilder(log_format=config.prompt.log_format)
        system_prompt = prompt_builder.build_system_prompt(
            chat_stream, tool_schemas=tool_schemas
        )
        request.add_payload(LLMPayload(ROLE.SYSTEM, Text(system_prompt)))

        # å†å²æ¶ˆæ¯ï¼ˆæ¥è‡ª stream contextï¼‰
        history_text = self._build_history_text(chat_stream)
        if history_text:
            history_content: Content | list[Content] = Text(history_text)
            # å¤šæ¨¡æ€æ¨¡å¼ï¼šæå–å†å²ä¸­çš„è¡¨æƒ…åŒ…/å›¾ç‰‡ä¸€å¹¶æ‰“åŒ…
            if is_unified and config.general.native_multimodal:
                from .multimodal import extract_media_from_messages, build_multimodal_content
                history_msgs = getattr(
                    getattr(chat_stream, "context", None), "history_messages", []
                )
                if history_msgs:
                    history_media = extract_media_from_messages(
                        history_msgs[-20:],
                        max_items=config.general.max_images_per_payload,
                    )
                    if history_media:
                        history_content = build_multimodal_content(
                            history_text, history_media
                        )
                        logger.debug(
                            f" å†å²å¤šæ¨¡æ€: æå–åˆ° {len(history_media)} å¼ å›¾ç‰‡/è¡¨æƒ…åŒ…"
                        )
            request.add_payload(LLMPayload(ROLE.USER, history_content))

        # â”€â”€ response = requestï¼ˆå»ºç«‹ response é“¾ï¼‰â”€â”€
        response = request

        # åŸç”Ÿå¤šæ¨¡æ€æ¨¡å¼ï¼šä»… unified æ¨¡å¼ç”Ÿæ•ˆ
        # split æ¨¡å¼çš„å†³ç­–æ­¥(sub_actor)é€šå¸¸ä¸æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼Œå› æ­¤ä¸è·³è¿‡ VLM è¯†åˆ«
        if is_unified and config.general.native_multimodal:
            try:
                from src.core.managers.media_manager import get_media_manager
                get_media_manager().skip_vlm_for_stream(self.stream_id)
            except Exception:
                logger.warning("æ³¨å†Œè·³è¿‡ VLM è¯†åˆ«å¤±è´¥ï¼Œåç»­æ¶ˆæ¯ä»ä¼šè§¦å‘ VLM")

        # â”€â”€ å¯¹è¯å¾ªç¯ â”€â”€
        mental_summary = ""  # æ´»åŠ¨æµæ‘˜è¦ï¼ˆunified å’Œ split å…±ç”¨ï¼‰
        media_items = None  # å¤šæ¨¡æ€å›¾ç‰‡ï¼ˆsplit æ¨¡å¼è·¨æ®µä¼ é€’ï¼‰
        timeout_payload = None  # è¶…æ—¶ payloadï¼ˆsplit æ¨¡å¼è·¨æ®µä¼ é€’ï¼‰

        while True:
            # é‡ç½® split æ¨¡å¼è·¨æ®µå˜é‡
            timeout_payload = None
            media_items = None
            mental_summary = ""

            # è¯»å–æœªè¯»æ¶ˆæ¯
            formatted_text, unread_msgs = await self.fetch_unreads()

            if formatted_text and unread_msgs:
                # è®°å½•ç”¨æˆ·æ¶ˆæ¯åˆ°æ´»åŠ¨æµ
                for msg in unread_msgs:
                    session.add_user_message(
                        content=getattr(msg, "processed_plain_text", "") or str(
                            getattr(msg, "content", "")
                        ),
                        user_name=getattr(msg, "sender_name", "ç”¨æˆ·"),
                        user_id=getattr(msg, "sender_id", ""),
                        timestamp=self._extract_timestamp(msg),
                    )

                # æ£€æŸ¥ç­‰å¾…æœŸé—´æ”¶åˆ°å›å¤çš„æ—¶æ•ˆ
                if session.is_waiting():
                    self._record_reply_timing(session)
                    session.clear_waiting()

                # å¤šæ¨¡æ€ï¼šæå–æœªè¯»æ¶ˆæ¯ä¸­çš„å›¾ç‰‡æ•°æ®ï¼ˆä»… unified æ¨¡å¼ç”Ÿæ•ˆï¼‰
                # split æ¨¡å¼çš„å†³ç­–æ­¥ä½¿ç”¨è½»é‡çº§ sub_actorï¼Œé€šå¸¸ä¸æ”¯æŒå¤šæ¨¡æ€ï¼Œ
                # å›å¤æ­¥è™½ä½¿ç”¨ä¸»æ¨¡å‹ä½†ä¸ä¼ å…¥å›¾ç‰‡ä»¥ä¿æŒä¸€è‡´æ€§
                media_items = None
                if is_unified and config.general.native_multimodal:
                    from .multimodal import extract_media_from_messages
                    raw_items = extract_media_from_messages(
                        unread_msgs,
                        max_items=config.general.max_images_per_payload,
                    )
                    media_items = raw_items or None
                    logger.debug(
                        f" åŸç”Ÿå¤šæ¨¡æ€: æå–åˆ° {len(raw_items)} å¼ å›¾ç‰‡"
                        + (f" (æˆªæ–­è‡³ {config.general.max_images_per_payload})"
                           if raw_items else "ï¼Œæœªè¯»æ¶ˆæ¯ä¸­æ— å›¾ç‰‡")
                    )

                # ç­–ç•¥æ„å»º user payload
                mental_summary = session.mental_log.format_as_summary(
                    max_entries=config.prompt.max_log_entries
                )

                if is_unified:
                    # unified æ¨¡å¼ï¼šå†³ç­–+å›å¤ä¸€ä½“ï¼Œpayload ç›´æ¥åŠ å…¥ä¸»é“¾
                    user_payload = strategy.build_user_payload(
                        formatted_unreads=formatted_text,
                        mental_log_summary=mental_summary,
                        media_items=media_items,
                    )
                    response.add_payload(user_payload)
                # split æ¨¡å¼ï¼špayload åœ¨ LLM è°ƒç”¨æ®µå¤„ç†ï¼Œæ­¤å¤„æš‚å­˜ä¸Šä¸‹æ–‡
                # mental_summary / formatted_text / media_items åœ¨ä¸‹æ–¹ split æ®µä½¿ç”¨

            elif session.is_waiting():
                # æ­£åœ¨ç­‰å¾…ä¸­ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¶…æ—¶æˆ–è¿ç»­æ€è€ƒ
                from .thinker.timeout_handler import TimeoutHandler

                timeout_handler = TimeoutHandler(config)
                if timeout_handler.check_timeout(session):
                    # è¶…æ—¶å¤„ç†
                    timeout_ctx = timeout_handler.handle_timeout(session)

                    if timeout_handler.should_give_up(session):
                        logger.info("è¿ç»­è¶…æ—¶æ¬¡æ•°è¿‡å¤šï¼Œç»“æŸå¯¹è¯")
                        await self._save_session(session)
                        self._unskip_vlm(config)
                        yield Stop(0)
                        return

                    # æ³¨å…¥è¶…æ—¶ payload
                    timeout_payload = strategy.generate_timeout_decision(
                        elapsed_seconds=timeout_ctx["elapsed_seconds"],  # type: ignore[arg-type]
                        expected_reaction=timeout_ctx["expected_reaction"],  # type: ignore[arg-type]
                        consecutive_timeouts=timeout_ctx["consecutive_timeouts"],  # type: ignore[arg-type]
                        pending_thoughts=timeout_ctx.get("pending_thoughts"),  # type: ignore[arg-type]
                    )

                    if is_unified:
                        # unified æ¨¡å¼ï¼šç›´æ¥åŠ å…¥ä¸»é“¾
                        response.add_payload(timeout_payload)
                    # split æ¨¡å¼ï¼štimeout_payload åœ¨ LLM è°ƒç”¨æ®µä½¿ç”¨
                else:
                    # æœªè¶…æ—¶ï¼Œç»§ç»­ç­‰å¾…ã€‚ä½¿ç”¨ Wait(0) è®©æ¡†æ¶åœ¨ä¸‹ä¸€ä¸ª tick ç«‹å³å”¤é†’ï¼Œ
                    # ä»¥ä¾¿åŠæ—¶å“åº”æ–°åˆ°è¾¾çš„æ¶ˆæ¯ï¼ˆæ¡†æ¶çš„ Wait(N) ä¼šå¿½ç•¥æ–°æ¶ˆæ¯ï¼‰ã€‚
                    # è¶…æ—¶åˆ¤æ–­ç”± session.waiting_config å†…éƒ¨è¿½è¸ªï¼Œä¸ä¾èµ–æ¡†æ¶è®¡æ—¶ã€‚
                    yield Wait(0)
                    continue
            else:
                # æ— æ¶ˆæ¯ä¸”ä¸åœ¨ç­‰å¾…ï¼ŒçŸ­ç­‰å¾…ä¸€ä¸ª tick å‘¨æœŸè®©æ¡†æ¶ç«‹å³å”¤é†’
                yield Wait(0)
                continue

            # â”€â”€ è°ƒç”¨ LLM â”€â”€
            if is_unified:
                # unified æ¨¡å¼ï¼šå•æ¬¡è°ƒç”¨ä¸»é“¾
                if config.debug.show_prompt:
                    self._log_prompt(response)

                try:
                    response = await response.send(stream=False)
                    await response
                    await self.flush_unreads(unread_msgs if unread_msgs else [])
                except Exception as e:
                    logger.error(f"LLM è¯·æ±‚å¤±è´¥: {e}", exc_info=True)
                    yield Failure("LLM è¯·æ±‚å¤±è´¥", e)
                    continue

                result = strategy.parse_response(
                    response_text=response.message or "",
                    call_list=response.call_list,
                )

                # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤º LLM å“åº”æ¦‚å†µ
                if config.debug.show_prompt:
                    call_count = len(response.call_list) if response.call_list else 0
                    call_names = [c.name for c in response.call_list] if response.call_list else []
                    msg_len = len(response.message or "")
                    logger.debug(
                        f"[KFC] LLM å“åº”: "
                        f"tool_calls={call_count} {call_names} | "
                        f"message_len={msg_len} | "
                        f"parsed_actions={[a.get('type') for a in result.actions]}"
                    )
            else:
                # â”€â”€ split æ¨¡å¼ï¼šå†³ç­–æ­¥(sub_actor) + å›å¤æ­¥(actor) â”€â”€
                from .strategies.split import SplitStrategy

                split_strategy = strategy if isinstance(strategy, SplitStrategy) else SplitStrategy()
                result, response = await self._split_llm_call(
                    split_strategy=split_strategy,
                    response=response,
                    decision_model_set=decision_model_set,  # type: ignore[arg-type]
                    system_prompt=system_prompt,
                    formatted_text=formatted_text or "",
                    mental_summary=mental_summary,
                    media_items=media_items,
                    timeout_payload=timeout_payload,
                    config=config,
                )
                await self.flush_unreads(unread_msgs if unread_msgs else [])

            # è¾“å‡ºå“åº”ç¾åŒ–æ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰
            self._log_strategy_result(result, config)

            # è®°å½•åˆ°æ´»åŠ¨æµ
            session.add_bot_planning(
                thought=result.thought,
                actions=result.actions,
                expected_reaction=result.expected_reaction,
                max_wait_seconds=result.max_wait_seconds,
            )

            # â”€â”€ å¤„ç†åŠ¨ä½œ â”€â”€
            _CORE_ACTION_TYPES = {_KFC_REPLY, "respond", "do_nothing"}
            trigger_msg = unread_msgs[-1] if unread_msgs else None

            for action in result.actions:
                action_type = action.get("type", "")
                if action_type in (_KFC_REPLY, "respond"):
                    # æ ¸å¿ƒåŠ¨ä½œï¼šå›å¤æ¶ˆæ¯
                    content = action.get("content", "")
                    if content:
                        await self._execute_reply(content, config, trigger_msg)
                elif action_type not in _CORE_ACTION_TYPES:
                    # ç¬¬ä¸‰æ–¹å·¥å…·ï¼šé€šè¿‡ JSON actions è°ƒç”¨ï¼ˆéåŸç”Ÿ Tool Callingï¼‰
                    args = {
                        k: v for k, v in action.items()
                        if k not in ("type", "reason")
                    }
                    logger.info(
                        f"JSON åŠ¨ä½œè°ƒç”¨ {action_type}ï¼Œ"
                        f"æƒ³æ³•: {result.thought[:50]}"
                    )
                    await self._execute_json_action(
                        action_type, args, usable_map, trigger_msg
                    )

            # æ—¢æ²¡æœ‰å›å¤ä¹Ÿæ²¡æœ‰å·¥å…·è°ƒç”¨ â†’ ç›´æ¥ç»“æŸ
            has_meaningful_action = any(
                a.get("type") in (_KFC_REPLY, "respond")
                or a.get("type") not in _CORE_ACTION_TYPES
                for a in result.actions
            )
            if not has_meaningful_action:
                if result.actions and result.actions[0].get("type") == "do_nothing":
                    logger.debug("ç­–ç•¥è¿”å› do_nothingï¼Œè·³è¿‡æœ¬è½®")
                elif response.message and response.message.strip():
                    logger.warning(
                        f"LLM è¿”å›æ— æ³•è§£æçš„å†…å®¹: {response.message[:100]}"
                    )
                self._unskip_vlm(config)
                yield Stop(0)
                await self._save_session(session)
                return

            # â”€â”€ ç­‰å¾…æ§åˆ¶ï¼ˆç»Ÿä¸€ç”± max_wait_seconds é©±åŠ¨ï¼‰ â”€â”€
            wait_seconds = config.wait.apply_rules(
                result.max_wait_seconds,
                session.consecutive_timeout_count,
            )

            if wait_seconds > 0:
                from .models import WaitingConfig

                waiting_config = WaitingConfig(
                    expected_reaction=result.expected_reaction,
                    max_wait_seconds=wait_seconds,
                    started_at=time.time(),
                )
                session.set_waiting(waiting_config)
                session.pending_thoughts.clear()
                await self._save_session(session)
                # Wait(0)ï¼šè®©æ¡†æ¶æ¯ä¸ª tick å”¤é†’ï¼Œè¶…æ—¶ç”± session.waiting_config è¿½è¸ª
                yield Wait(0)
                continue

            # max_wait_seconds <= 0 â†’ è¯é¢˜ç»“æŸï¼Œä¸å†ç­‰å¾…
            session.clear_waiting()
            await self._save_session(session)
            self._unskip_vlm(config)
            yield Stop(0)
            return

    def _unskip_vlm(self, config: KFCConfig) -> None:
        """æ¢å¤è¯¥èŠå¤©æµçš„ VLM è¯†åˆ«ï¼ˆå¯¹è¯ç»“æŸæ—¶æ¸…ç†ï¼‰ã€‚"""
        if config.general.native_multimodal:
            try:
                from src.core.managers.media_manager import get_media_manager
                get_media_manager().unskip_vlm_for_stream(self.stream_id)
            except Exception:
                pass

    async def _execute_json_action(
        self,
        action_type: str,
        args: dict[str, Any],
        usable_map: Any,
        trigger_msg: Any | None,
    ) -> None:
        """æ‰§è¡Œ JSON actions ä¸­çš„ç¬¬ä¸‰æ–¹å·¥å…·è°ƒç”¨ã€‚

        é€šè¿‡ usable_map æŸ¥æ‰¾å·¥å…·ç±»ï¼Œä½¿ç”¨ exec_llm_usable æ‰§è¡Œã€‚
        ç»“æœä»…è®°å½•æ—¥å¿—ï¼Œä¸å›ä¼  LLMï¼ˆä¸åŸç”Ÿ Tool Calling ä¸åŒï¼‰ã€‚

        Args:
            action_type: åŠ¨ä½œç±»å‹åç§°ï¼ˆå³å·¥å…·åï¼‰
            args: åŠ¨ä½œå‚æ•°ï¼ˆå·²å»é™¤ type å’Œ reason å­—æ®µï¼‰
            usable_map: å·¥å…·æ³¨å†Œè¡¨
            trigger_msg: è§¦å‘æ¶ˆæ¯
        """
        usable_cls = usable_map.get(action_type)
        if not usable_cls:
            logger.warning(f"JSON åŠ¨ä½œ {action_type} æœªæ‰¾åˆ°å¯¹åº”å·¥å…·ï¼Œè·³è¿‡")
            return

        try:
            if trigger_msg is None:
                trigger_msg = await self._get_virtual_trigger_message()
                if trigger_msg is None:
                    logger.warning(f"æ‰§è¡Œ {action_type} å¤±è´¥: æ— è§¦å‘æ¶ˆæ¯")
                    return

            success, result = await self.exec_llm_usable(
                usable_cls, trigger_msg, **args
            )
            if success:
                logger.info(f"JSON åŠ¨ä½œ {action_type} æ‰§è¡ŒæˆåŠŸ: {str(result)[:100]}")
            else:
                logger.warning(f"JSON åŠ¨ä½œ {action_type} æ‰§è¡Œå¤±è´¥: {result}")
        except Exception as e:
            logger.error(f"JSON åŠ¨ä½œ {action_type} æ‰§è¡Œå¼‚å¸¸: {e}", exc_info=True)

    async def _execute_reply(
        self,
        content: str,
        config: KFCConfig,
        trigger_msg: Any | None = None,
    ) -> None:
        """é€šè¿‡æ¡†æ¶æ ‡å‡†è·¯å¾„å‘é€å›å¤ã€‚

        Args:
            content: å›å¤æ–‡æœ¬å†…å®¹
            config: KFC é…ç½®ï¼ˆKFCReplyAction ä» plugin.config è‡ªè¡Œè¯»å–ï¼‰
            trigger_msg: è§¦å‘æ¶ˆæ¯ï¼Œä¸º None æ—¶æ„é€ è™šæ‹Ÿæ¶ˆæ¯
        """
        from .actions.reply import KFCReplyAction

        if trigger_msg is None:
            trigger_msg = await self._get_virtual_trigger_message()
            if trigger_msg is None:
                logger.warning("æ— è§¦å‘æ¶ˆæ¯ï¼Œæ— æ³•å‘é€å›å¤")
                return

        try:
            await self.exec_llm_usable(KFCReplyAction, trigger_msg, content=content)
        except Exception as e:
            logger.error(f"é€šè¿‡æ¡†æ¶æ‰§è¡Œ KFCReplyAction å¤±è´¥: {e}", exc_info=True)

    async def _split_llm_call(
        self,
        split_strategy: Any,
        response: Any,
        decision_model_set: Any,
        system_prompt: str,
        formatted_text: str,
        mental_summary: str,
        media_items: Any,
        timeout_payload: Any,
        config: KFCConfig,
    ) -> tuple[Any, Any]:
        """Split æ¨¡å¼ä¸¤æ­¥ LLM è°ƒç”¨ï¼šå†³ç­–(sub_actor) + å›å¤(actor)ã€‚

        1. å†³ç­–æ­¥ï¼šåˆ›å»ºä¸€æ¬¡æ€§ sub_actor è¯·æ±‚ï¼Œå‘é€å†³ç­– payloadï¼Œè·å– JSON å†³ç­–
        2. å›å¤æ­¥ï¼šå¦‚æœå†³ç­–è¦æ±‚å›å¤ï¼Œå°†å›å¤ payload åŠ å…¥ä¸»é“¾(actor)å‘é€ï¼Œè·å–å›å¤å†…å®¹

        Args:
            split_strategy: SplitStrategy å®ä¾‹
            response: ä¸» response é“¾ï¼ˆactor æ¨¡å‹ï¼‰
            decision_model_set: å†³ç­–æ¨¡å‹é…ç½®ï¼ˆsub_actorï¼‰
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            formatted_text: æ ¼å¼åŒ–çš„æœªè¯»æ¶ˆæ¯æ–‡æœ¬
            mental_summary: æ´»åŠ¨æµæ‘˜è¦
            media_items: å¤šæ¨¡æ€å›¾ç‰‡åˆ—è¡¨
            timeout_payload: è¶…æ—¶å†³ç­– payloadï¼ˆéè¶…æ—¶åœºæ™¯ä¸º Noneï¼‰
            config: KFC é…ç½®

        Returns:
            tuple[StrategyResult, response]: è§£æç»“æœå’Œæ›´æ–°åçš„ response é“¾
        """
        from .models import StrategyResult

        # â”€â”€ å†³ç­–æ­¥ï¼šsub_actor ä¸€æ¬¡æ€§è¯·æ±‚ â”€â”€
        decision_request = create_llm_request(decision_model_set, "kfc_decision")
        decision_request.add_payload(LLMPayload(ROLE.SYSTEM, Text(system_prompt)))

        if timeout_payload is not None:
            # è¶…æ—¶åœºæ™¯ï¼šä½¿ç”¨è¶…æ—¶å†³ç­– payload
            decision_request.add_payload(timeout_payload)
        elif formatted_text:
            # æ­£å¸¸æ¶ˆæ¯åœºæ™¯ï¼šä½¿ç”¨å†³ç­– payloadï¼ˆå« JSON æŒ‡ä»¤ï¼‰
            decision_payload = split_strategy.build_user_payload(
                formatted_unreads=formatted_text,
                mental_log_summary=mental_summary,
                media_items=media_items,
            )
            decision_request.add_payload(decision_payload)
        else:
            # æ— æ¶ˆæ¯ä¹Ÿæ— è¶…æ—¶ï¼ˆä¸åº”åˆ°è¾¾æ­¤å¤„ï¼‰
            return StrategyResult.create_error("split æ¨¡å¼æ— å¯ç”¨è¾“å…¥"), response

        if config.debug.show_prompt:
            self._log_prompt(decision_request)

        try:
            decision_response = await decision_request.send(stream=False)
            await decision_response
        except Exception as e:
            logger.error(f"Split å†³ç­–æ­¥ LLM è¯·æ±‚å¤±è´¥: {e}", exc_info=True)
            return StrategyResult.create_error(f"å†³ç­–è¯·æ±‚å¤±è´¥: {e}"), response

        result = split_strategy.parse_response(
            response_text=decision_response.message or "",
        )

        logger.debug(
            f"Split å†³ç­–: thought={result.thought[:50]}, "
            f"actions={[a.get('type') for a in result.actions]}"
        )

        # â”€â”€ å›å¤æ­¥ï¼šä»…åœ¨å†³ç­–è¦æ±‚å›å¤æ—¶ï¼Œä½¿ç”¨ actor ä¸»é“¾ç”Ÿæˆ â”€â”€
        needs_reply = any(
            a.get("type") in (_KFC_REPLY, "respond") for a in result.actions
        )

        if needs_reply and formatted_text:
            # æ„å»ºå›å¤ payloadï¼ˆä¸å« JSON æŒ‡ä»¤ï¼‰ï¼ŒåŠ å…¥ä¸»é“¾
            reply_payload = split_strategy.build_reply_payload(
                formatted_unreads=formatted_text,
                mental_log_summary=mental_summary,
                media_items=media_items,
            )
            response.add_payload(reply_payload)

            try:
                response = await response.send(stream=False)
                await response
            except Exception as e:
                logger.error(f"Split å›å¤æ­¥ LLM è¯·æ±‚å¤±è´¥: {e}", exc_info=True)
                return StrategyResult.create_error(f"å›å¤è¯·æ±‚å¤±è´¥: {e}"), response

            # ç”¨ä¸»é“¾ç”Ÿæˆçš„å›å¤å†…å®¹æ›¿æ¢å†³ç­–ä¸­çš„ kfc_reply content
            reply_content = response.message or ""
            for action in result.actions:
                if action.get("type") in (_KFC_REPLY, "respond"):
                    action["content"] = reply_content

        elif needs_reply and timeout_payload is not None:
            # è¶…æ—¶åœºæ™¯ï¼šå†³ç­–è¦æ±‚è¿½é—®ï¼Œç”¨å†³ç­–ä¸­çš„ content ä½œä¸ºå›å¤
            # ï¼ˆå†³ç­– JSON ä¸­å·²åŒ…å« content å­—æ®µï¼‰
            pass

        return result, response

    async def _get_virtual_trigger_message(self) -> Any:
        """æ„é€ è™šæ‹Ÿè§¦å‘æ¶ˆæ¯ï¼Œç”¨äºè¶…æ—¶ä¸»åŠ¨å‘è¨€ç­‰æ— çœŸå®è§¦å‘æ¶ˆæ¯çš„åœºæ™¯ã€‚"""
        from src.core.managers.stream_manager import get_stream_manager

        sm = get_stream_manager()
        chat_stream = sm._streams.get(self.stream_id)
        if not chat_stream:
            return None

        context = getattr(chat_stream, "context", None)
        # ä»å†å²æ¶ˆæ¯ä¸­å–æœ€åä¸€æ¡ä½œä¸ºè™šæ‹Ÿè§¦å‘
        if context and hasattr(context, "history_messages") and context.history_messages:
            return context.history_messages[-1]

        # å®åœ¨æ²¡æœ‰æ¶ˆæ¯ï¼Œæ„é€ æœ€å°åŒ– Message å¯¹è±¡
        from src.core.models.message import Message

        return Message(
            message_id="virtual_timeout_trigger",
            platform=chat_stream.platform or "unknown",
            stream_id=self.stream_id,
            sender_id="system",
            sender_name="system",
            content="[è¶…æ—¶è§¦å‘]",
            processed_plain_text="[è¶…æ—¶è§¦å‘]",
        )

    async def _save_session(self, session: KFCSession) -> None:
        """ä¿å­˜ Sessionï¼ˆæŒæœ‰ per-stream é”ï¼‰ã€‚"""
        store = self._get_session_store()
        async with store.lock(session.stream_id):
            await store.save(session)

    @staticmethod
    def _build_history_text(chat_stream: ChatStream) -> str:
        """ä» chat_stream context æ„å»ºå†å²æ¶ˆæ¯æ–‡æœ¬ã€‚"""
        from datetime import datetime

        history_messages = getattr(
            getattr(chat_stream, "context", None),
            "history_messages",
            [],
        )
        if not history_messages:
            return ""

        lines: list[str] = []
        for msg in history_messages:
            raw_time = getattr(msg, "time", None)
            if isinstance(raw_time, (int, float)):
                try:
                    time_str = datetime.fromtimestamp(raw_time).strftime("%Y-%m-%d %H:%M:%S")
                except (OSError, ValueError, OverflowError):
                    time_str = str(raw_time)
            else:
                time_str = str(raw_time or "")
            sender = getattr(msg, "sender_name", "æœªçŸ¥")
            text = getattr(msg, "processed_plain_text", "")
            lines.append(f"ã€{time_str}ã€‘{sender}: {text}")

        return "ä»¥ä¸‹ä¸ºæœ€è¿‘çš„èŠå¤©å†å²è®°å½•ï¼š\n" + "\n".join(lines)

    @staticmethod
    def _extract_timestamp(msg: Any) -> float:
        """ä»æ¶ˆæ¯å¯¹è±¡æå–æ—¶é—´æˆ³ã€‚"""
        raw_time = getattr(msg, "time", None)
        if isinstance(raw_time, (int, float)):
            return float(raw_time)
        if raw_time is not None:
            try:
                return float(raw_time)
            except (TypeError, ValueError):
                pass
        return time.time()

    @staticmethod
    def _record_reply_timing(session: KFCSession) -> None:
        """è®°å½•å›å¤æ—¶æ•ˆåˆ°æ´»åŠ¨æµã€‚"""
        from .mental_log import MentalLogEntry
        from .models import KFCEventType

        elapsed = session.waiting_config.get_elapsed_seconds()
        max_wait = session.waiting_config.max_wait_seconds

        if elapsed <= max_wait:
            event_type = KFCEventType.REPLY_IN_TIME
        else:
            event_type = KFCEventType.REPLY_LATE

        entry = MentalLogEntry(
            event_type=event_type,
            timestamp=time.time(),
            elapsed_seconds=elapsed,
        )
        session.mental_log.add(entry)

    # â”€â”€ è°ƒè¯•æ—¥å¿—æ–¹æ³• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _log_prompt(self, response: Any) -> None:
        """è¾“å‡ºå‘é€ç»™ LLM çš„å®Œæ•´æç¤ºè¯ï¼ˆé¢æ¿æ ¼å¼ï¼‰ã€‚"""
        prompt_text = self._format_prompt_for_log(response)
        logger.print_panel(
            prompt_text,
            title=f"KFC æç¤ºè¯ (stream={self.stream_id[:8]})",
            border_style="cyan",
        )

    @staticmethod
    def _format_prompt_for_log(response: Any) -> str:
        """ä» LLM request/response çš„ payload åˆ—è¡¨ä¸­æå–å¹¶æ ¼å¼åŒ–æç¤ºè¯ã€‚"""
        _MAX_CONTENT_LEN = 10000

        payloads = getattr(response, "payloads", None)
        if not payloads:
            return "ï¼ˆæ—  payloadï¼‰"

        parts: list[str] = []
        for payload in payloads:
            # æå–è§’è‰²å
            role = getattr(payload, "role", None)
            role_name = str(role.value).upper() if hasattr(role, "value") else str(role)

            # payload.content æ˜¯ list[Content | LLMUsable]
            content_list = getattr(payload, "content", [])
            if not isinstance(content_list, list):
                content_list = [content_list]

            # éå†æ¯ä¸ª content å…ƒç´ æå–æ–‡æœ¬
            text_parts: list[str] = []
            tool_names: list[str] = []
            for item in content_list:
                if hasattr(item, "text"):
                    # Text å¯¹è±¡
                    text_parts.append(item.text)
                elif hasattr(item, "value") and hasattr(item, "__class__") and item.__class__.__name__ == "Image":
                    # Image å¯¹è±¡ï¼šåªæ˜¾ç¤ºæ‘˜è¦ï¼Œä¸è¾“å‡ºå®Œæ•´ base64
                    data_preview = str(item.value)[:40]
                    text_parts.append(f"[å›¾ç‰‡: {data_preview}...]")
                elif hasattr(item, "to_text"):
                    # ToolResult å¯¹è±¡
                    text_parts.append(item.to_text())
                elif hasattr(item, "to_schema"):
                    # LLMUsableï¼ˆå·¥å…·å®šä¹‰ï¼‰ï¼Œè®°å½•åç§°
                    schema = item.to_schema()
                    func_info = schema.get("function", schema)
                    name = func_info.get("name", type(item).__name__)
                    tool_names.append(name)
                else:
                    text_parts.append(str(item))

            # ç»„åˆè¾“å‡º
            tool_count = len(tool_names)
            tool_summary = f"[{tool_count} ä¸ªå·¥å…·: {', '.join(tool_names)}]" if tool_names else ""
            if tool_count > 0 and not text_parts:
                text = tool_summary
            elif tool_count > 0:
                text = "\n".join(text_parts) + f"\n[+ {tool_summary}]"
            elif text_parts:
                text = "\n".join(text_parts)
            else:
                text = "ï¼ˆç©ºï¼‰"

            # æˆªæ–­è¿‡é•¿å†…å®¹
            if len(text) > _MAX_CONTENT_LEN:
                text = text[:_MAX_CONTENT_LEN] + "\n[...æˆªæ–­...]"

            parts.append(f"â”€â”€ {role_name} â”€â”€\n{text}")

        return "\n\n".join(parts)

    @staticmethod
    def _log_strategy_result(result: StrategyResult, config: KFCConfig) -> None:
        """ç¾åŒ–è¾“å‡º LLM å“åº”æ‘˜è¦ã€‚"""
        if not config.debug.show_response:
            return

        # å†…å¿ƒæƒ³æ³•
        if result.thought:
            logger.info(
                f"[bold magenta]ğŸ’­[/bold magenta] {result.thought}"
            )

        # åŠ¨ä½œåˆ—è¡¨
        for action in result.actions:
            action_type = action.get("type", "")
            if action_type in ("kfc_reply", "respond"):
                content = action.get("content", "")
                if content:
                    logger.info(
                        f"[bold green]ğŸ’¬[/bold green] {content}"
                    )
            elif action_type == "kfc_wait":
                logger.info(
                    "[bold yellow]â³[/bold yellow] ç­‰å¾…å¯¹æ–¹å›å¤"
                )
            elif action_type == "kfc_stop":
                logger.info(
                    "[bold red]ğŸ›‘[/bold red] ç»“æŸå¯¹è¯"
                )
            elif action_type not in ("do_nothing", "no_action"):
                logger.info(
                    f"[bold cyan]ğŸ¯[/bold cyan] {action_type}"
                )

        # å…ƒæ•°æ®
        meta_parts: list[str] = []
        if result.max_wait_seconds > 0:
            meta_parts.append(f"â± {result.max_wait_seconds:.0f}s")
        if result.expected_reaction:
            meta_parts.append(f"é¢„æœŸ: {result.expected_reaction}")
        if result.mood:
            meta_parts.append(f"å¿ƒæƒ…: {result.mood}")
        if meta_parts:
            logger.info(f"[dim]{' | '.join(meta_parts)}[/dim]")
